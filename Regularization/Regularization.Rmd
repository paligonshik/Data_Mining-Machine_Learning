---
title: "REgularization Methods (Ridge,Lasso and Elastic Net)"
author: "Vazgen Tadevosyan"
date: "March 26, 2019"
output:
  pdf_document: default
  html_document: default
---
```
For this Homework, you are required to submit both Markdown and HTML files with your answers and code in it. Be sure that the .Rmd file is working, so when I run it, there would be no errors and represent the same information as HTML. Write your code and interpretations under each question. The interpretations of the results need to be written below or above all the charts, summaries, or tables. Do not remove problems from your Markdown file. 

Use movies_data.xls dataset uploaded on Moodle to analyze the relationship between the target variable and different factors. The description of the variables is given in a separate file. Pay close attention to the names of axes, titles, and labels. <p>
```

<b> Problem 1. 3 pt. </b> <p>
```
a. Fit a linear model using least squares on the training set, and report the test error obtained. 
b. What is regularization? Why we need it?

```
```{r,message=FALSE}
library(readxl)
library(dplyr)
library(plyr)
library(zoo)
library(Metrics)
```


a.
```{r,echo = T, results = 'hide'}

data<-read_excel("movies_data.xls",na=c('#DIV/0',"#DIV/0!","#NAME?", 'NA',"N/A",""," "))
data$genre_first<-factor(data$genre_first)
data$Country<-factor(data$Country)
data$Rated<-factor(data$Rated)
data$Rated<-revalue(data$Rated, c("NOT RATED"="UNRATED"))
data$genre_first<-factor(data$genre_first)
data$Production<-factor(data$Production)
data$OscarWon<-factor(data$OscarWon)
data$Oscar_binary<-ifelse(data$OscarNom==0,0,1)
data<-data%>% mutate_if(is.numeric , na.aggregate)
data<-na.omit(data)
df<-data %>% dplyr::select(-c(Writer,Production,index,Country,OscarWon,Oscar_binary,OscarNom,Director,Plot,Language,Awards,gross,budget,Release,DVD,Release_Month,Release_Day,Release_year,Actors,Genre,title,OtherWin,OtherNom,imdbVotes,Metascore,duration,cast_facebook_likes,Rated))

```

```{r}
set.seed(42)
index<-sample(nrow(df),nrow(df)*.75,replace = F)
train<-df[index,]
test<-df[-index,]
options(scipen=999)
model<-lm(gross_adjusted~genre_first+imdbRating+year+budget_adjusted+reviews,data = train)
summary(model)
pred<-predict(model,test)
actual<-test$gross_adjusted
rmse(actual,pred)
```



b.
*Regularization is a technique that is used to avoid overfitting. It introduces small amount of bias into how new line is fit to the data.But in return for that we get a significant drop in Variance.*
*Rmse for the test is 66139797*

<b>Problem 2. 5 pt. </b> <p>
```
a. Fit a ridge regression model on the training set, with lambda chosen by cross-validation. Report the test error obtained.

b. Describe the main idea of ridge regression.
```

a.
```{r}
library(glmnet)
set.seed(42)
y_train<-train$gross_adjusted 
x_train<-model.matrix(~.,subset(train,select =-gross_adjusted))
y_test<-test$gross_adjusted
x_test<-model.matrix(~.,subset(test,select =-gross_adjusted))
lambdas<-seq(from=0,to = 10,by = 0.001)
x <- model.matrix( ~ .-gross_adjusted, df)
cros_ridge<-cv.glmnet(x =x,y=df$gross_adjusted,alpha=0,lambda = lambdas,nfolds = 10)
ridge<-glmnet(x = x_train,y=y_train,lambda=cros_ridge$lambda.min,alpha = 0)
pred_r<-predict(ridge,newx = x_test )
rmse(y_test,pred_r)
```
b.
$$\sum_{i=1}^{n} \left( y_i - \beta_0 - \sum_{j=1}^p \beta_j x_{ij} \right)^2+\lambda*\sum_{j=1}^{k}\hat{\beta_j}^2= $$$$=SSR+\lambda*\sum_{j=1}^{k}\hat{\beta_j}^2$$
Ridge regression is adding a penalty term to our loss function.
$\lambda*\sum_{j=1}^{k}\hat{\beta_j}^2$ *is a shrinkage penalty.* 
*where*$\lambda\ge0$*is a tuning parameter.*
*This has the effect of shrinking large values of the coefficients towards zero.So our dependent variable becomes less sensitive to predictors.As* $\lambda$ *increases the flexibility of the ridge regression fit decreases, leading to decreased variance but increased bias.Thus,we should get optimal value of *$\lambda$.
*Rmse for the test is 66139237 *

<b>Problem 3. 5 pt. </b> <p>


```
a. Fit a lasso model on the training set, with lambda chosen by cross-validation. Report the test error obtained, along with the number of non-zero coefficient estimates.

b. What is the difference between ridge and lasso regression?
```
```{r}
lambdas<-seq(from=0,to = 10,by = 0.001)
cros_lasso<-cv.glmnet(x =x,y=df$gross_adjusted,alpha=1,lambda = lambdas,nfolds = 10)
lasso<-glmnet(x = x_train,y=y_train,lambda=cros_lasso$lambda.min,alpha = 1)
pred_l<-predict(lasso,newx = x_test )
rmse(y_test,pred_l)
sum(lasso$beta!=0)

```

*Number of nonzero coeficients are 18 for lasso regression.*
b.*Ridge regression's penalty term will never force any of the coefficients to be exactly zero. Thus the final model will include all variables, whick makes it harder to interpret. Meanwhile the LASSO make some coefficients end up being set to exactly zero. The LASSO works in a similar way as Ridge,except it uses a different penalty term.*
$SSR+\lambda*\sum_{j=1}^{k}|\hat{\beta_j}|$<br>
*where*$\lambda\ge0$ * is a tuning parameter.*
*So, the Lasso Regression can exclude uselss variables from equation.*
*Rmse for the test is 66139237 *

<b>Problem 4. 7 pt. </b> <p>

```
a. Find the best elastic net regression with alpha chosen by cross-validation.
b. Is there much difference among the test errors resulting from these four approaches. Which one is the best?
```

```{r}
alphas=seq(from=0,to=1,length.out = 11)^3
library(glmnetUtils)
library(data.table)

# make some dummy data
output.of.cva.glmnet <- cva.glmnet(x =x,y=df$gross_adjusted,alpha = alphas)
number.of.alphas.tested <- length(output.of.cva.glmnet$alpha)
cv.glmnet.dt <- data.table()
for (i in 1:number.of.alphas.tested){
  glmnet.model <- output.of.cva.glmnet$modlist[[i]]
  min.mse <-  min(glmnet.model$cvm)
  min.lambda <- glmnet.model$lambda.min
  alpha.value <- output.of.cva.glmnet$alpha[i]
  new.cv.glmnet.dt <- data.table(alpha=alpha.value,min_mse=min.mse,min_lambda=min.lambda)
  cv.glmnet.dt <- rbind(cv.glmnet.dt,new.cv.glmnet.dt)
}
best.params <- cv.glmnet.dt[which.min(cv.glmnet.dt$min_mse)]
elast<-glmnet(x = x_train,y=y_train,lambda=best.params$min_lambda,alpha = best.params$alpha)
pred_l<-predict(elast,newx = x_test)
rmse(y_test,pred_l)

```
*Rmse for the test is 66124701*

*There is not much differences among the test errors resulting from these four approaches, however the best model according to RMSE is elastic net with alpha=0.729 and lambda=0.008*

<b> Bonus 2 pt. </b>

```
Is there any relationship between the variance of ridge estimation and the variance of OLS estimation? Show/prove it.
```

$Var(\hat{\beta}_{ols})=\sigma^{2}(X^TX)^{-1}$
$Var(\hat{\beta}_{ridge})=\sigma^{2}(X^TX+\lambda I)^{-1}X^TX(X^TX+\lambda I)^{-1}$<br>
Note that $\lambda\ge0$
From this equations we can state  $Var(\hat{\beta}_{ridge})\le Var(\hat{\beta}_{ols})$<br>
as $X^TX(X^TX+\lambda I)^{-1}\ge\sigma^{2}(X^TX+\lambda I)^{-1}$ <br>
$X^TX(X^TX+\lambda I)^{-1}$ is in denominator.So as big is $\lambda$ less is variance.






