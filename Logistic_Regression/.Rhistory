library(ggplot2)
library(dplyr)
library(tidyr)
library(zoo)
library(ggcorrplot)
library(gridExtra)
df<-read.csv("biodata.csv",na.strings = "?")
df<-df %>% dplyr::select(-c(sc, pcv,pe,id))
df$su<-ordered(df$su,levels=c(0,1,2,3,4,5))
df$class<-factor(df$class)
#sapply(df, function(x) sum(is.na(x)))
#df[duplicated(df$id),][1]
#sapply(df, function(x) sum(is.na(x)))
df<-df%>% mutate_if(is.numeric , na.aggregate)
df<-na.omit(df)
g1=ggplot(data = df, aes(x = class, y = rbcc,color = class))+
geom_boxplot()+
scale_x_discrete(labels= levels(df$class))+scale_y_continuous(limits=c(2, 8))+
stat_summary(fun.y = "mean",geom = 'point',col='red', shape=17, size=4)+
labs(title =" Red blood cell count by Presence of Kidney disease" ,y='red blood cell count',x=" Presence of  disease",color="Presence of disease")+
theme(plot.title = element_text(hjust = 0.5))+coord_flip()
g2 = ggplot(data = df, aes(x = class, y = hemo,color = class))+
geom_boxplot()+
scale_x_discrete(labels= levels(df$class) )+
stat_summary(fun.y = "mean",geom = 'point',col='blue', shape=12, size=4)+
labs(title ="Hemoglobin  by Presence of Kidney disease" ,color =  "Presence of disease",y='Hemoglobin',x="Presence of disease")+theme(plot.title = element_text(hjust = 0.5))+coord_flip()
grid.arrange(g1, g2,nrow=1)
model<-glm(class~hemo,data = df,family = 'binomial')
summary(model)
exp(coef(model))
sigmoid <- function (x) 1 / (1 + exp(-21.6504+1.6078 * x))
x<-runif(min = 3.1,max = 17.8,n=100)
plot(x, sigmoid(x), col='blue')
probs<-predict(model,data.frame(hemo=x),type='response')
new<-data.frame("Hemoglobin"=x,"Probabilities"=probs)
new$class<-ifelse(new$Probabilities>0.5,1,0)
ggplot(new,aes(y=factor(class),x=Hemoglobin))+geom_point()+geom_line(aes(y=Probabilities+1))+labs(y="Class")
model<-glm(class~rbc,data = df,family = "binomial")
summary(model)
probabilityOfbase<-predict(model,newdata = data.frame(rbc='abnormal'),type = 'response')
print(probabilityOfbase)
addmargins(table(df$rbc,df$class))
p1gn<-103/232
p1ga<-80/90
oddsnormal<-p1gn/(1-p1gn)
oddsabnormal<-p1ga/(1-p1ga)
rat<-oddsnormal/oddsabnormal
print(rat)
exp(coef(model))
set.seed(1)
library(MASS)
str(df)
model_full<-glm(class~.,data=df,family = 'binomial')
model_AIC<-stepAIC(model_full,direction = 'backward')
summary(model_AIC)
final<-glm(class ~rbc + bgr + hemo,data=df,family = 'binomial')
summary(final)
predict(final,newdata = data.frame(bp=mean(df$bp),rbc='normal',bgr=mean(df$bgr),hemo=mean(df$hemo),rbcc=mean(df$rbcc),cad='no'),type = 'response')
nullmod <- glm(class~1,data = df, family="binomial")
R2McFadden<-1-logLik(final)/logLik(nullmod)
R2McFadden
library(caret)
set.seed(1)
train_index<-createDataPartition(df$class,p = 0.7,list = F)
train<-df[train_index,]
test<-df[-train_index,]
table(train$class)/sum(table(train$class))
table(test$class)/sum(table(test$class))
#in this case our benchmark is 56 percent accuracy.
model<-glm(final$formula,data = train,family = 'binomial')
modelAIC<-glm(model_AIC$formula,data = train,family = 'binomial')
pred<-predict(model,newdata = test,type = 'response')
pred_class<-ifelse(pred>0.5,1,0)
conf<-addmargins(table(test$class,pred_class))
Accuracy<-sum(c(conf[1,1],conf[2,2]))/conf[3,3]
conf
sensitivity<-50/54
specificity<-39/41
print(paste("Overall accuracy is",Accuracy,"Sensitivity is",sensitivity,"and specificity" ,specificity))
confusionMatrix(as.factor(pred_class),test$class,positive = "1")
pred
prediction(pred,test$class)
library(ROCR)
ROC<-performance(p_test,"rec","fpr")
plot(ROC,colorize=T)
performance(p_test,"rec","fpr")@y.values
performance(p_test,"auc")@y.values
plot(performance(p_test,"auc"))
plot(performance(p_test,"auc")))
plot(performance(p_test,"auc"))
plot(performance(p_test,"roc"))@y.values
performance(p_test,"auc"))@y.values
performance(p_test,"roc")@y.values
performance(p_test,"auc")@y.values
performance(p_test,"roc")@y.values
?performance
?performance
performance(p_test,"ROC")@y.values
performance(p_test,"roc")@y.values
performance(p_test,"prec","rec")@y.values
performance(p_test,"roc")@y.values
performance(p_test,"roc")@y.values
performance(p_test,"auc")@y.values
performance(p_test,"roc")@y.values
p_test<-prediction(pred,test$class)
performance(p_test,"auc")@y.values
performance(p_test)@y.values
plot(p_test,colorize=T)
plot(ROC,colorize=T)
performance(p_test,"auc")@y.values
performance(p_test,"rmse")@y.values
performance(p_test,"auc")@y.values
ROC<-performance(p_test,"rec","fpr")
FPR<-unlist(ROC@x.values)
TPR<-unlist(ROC@y.values)
alpha<-unlist(ROC@alpha.values)
df<-data.frame(FPR,TPR,alpha)
head(df)
ggplot(df,aes(FPR,TPR,color=alpha))+geom_line()
ggplot(df,aes(FPR,TPR,color=alpha))+geom_line()+ggtitle("Relationship between TPR and FPR")
library(pROC)
rrr<-roc(test$class,pred_class)
g1<-ggroc(rrr,alpha = 0.5, colour = "green", linetype = 1, size = 1)+ggtitle("ROC curve for Model")
g1
g1<-ggroc(rrr,alpha = 0.5, colour = "green", linetype = 1, size = 1,print.cutoffs.at=seq(0,1,by=0.1))+ggtitle("ROC curve for Model")
plot(ROC,colorize=T,print.cutoffs.at=seq(0,1,by=0.1))
plot(ROC,colorize=T,print.cutoffs.at=seq(0,1,by=0.2))
